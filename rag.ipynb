{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RalfH1388/genai-lecture/blob/main/rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ykl8Ll3c6vww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e03d619-34ea-410b-bc8f-e033f4e6fa26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: cudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "Ym8jfxmCGHWz",
        "outputId": "6fe234da-9f24-4028-af10-baeac111a3cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4c9Oe7l32gf0"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#from dotenv import load_dotenv\n",
        "#load_dotenv()\n",
        "#OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('apikey_rh')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "9u8WePp87ZQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IVLOVSkZ2gf1"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeoTvWd52gf2"
      },
      "outputs": [],
      "source": [
        "model.invoke(\"Wie funktioniert ein Ottomotor?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYsfQwu_2gf2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = model | parser\n",
        "chain.invoke(\"Wie funktioniert ein Ottomotor?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "bzyb8Q9j2gf3",
        "outputId": "99987f86-f109-41d3-eebe-edc10126b5b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: \\nBeantworte die Frage basierend auf dem Kontext.\\nWenn Du die Frage nicht beantworten kannst, antworte \"Ich weiß es nicht\".\\n\\nContext: Ralfs Bruder heißt Axl.\\n\\nQuestion: Wer ist Ralfs Bruder?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Beantworte die Frage basierend auf dem Kontext.\n",
        "Wenn Du die Frage nicht beantworten kannst, antworte \"Ich weiß es nicht\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt.format(context=\"Ralfs Bruder heißt Axl.\", question=\"Wer ist Ralfs Bruder?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yLvqUhAb2gf4",
        "outputId": "e0c116a0-cc94-4aad-d847-f13c35c591dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ralfs Bruder ist Axl.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chain = prompt | model | parser\n",
        "chain.invoke({\n",
        "    \"context\": \"Ralfs Bruder heißt Axl\",\n",
        "    \"question\": \"Wer ist Ralfs Bruder?\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GzNNtXgQ2gf5"
      },
      "outputs": [],
      "source": [
        "translation_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate {answer} to {language}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lGBkJ1xe2gf5",
        "outputId": "8837e23a-9968-47a9-855b-d1c28fe795a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ralf's brother Axl has two other siblings, so Ralf has a total of three siblings.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "translation_chain = (\n",
        "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
        ")\n",
        "\n",
        "translation_chain.invoke(\n",
        "    {\n",
        "        \"context\": \"Ralfs Bruder heißt Axl. Er hat zwei weitere Geschwister.\",\n",
        "        \"question\": \"Wie viele Geschwister hat Ralf?\",\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BLLqHtA2gf6"
      },
      "source": [
        "Let's read the transcription and display the first few characters to ensure everything works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XZC-Twgf2gf6",
        "outputId": "5455fc67-d921-43a1-d5f3-8bff9cc1fd34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I think it's possible that physics has exploits and we should be trying to find them. arranging some\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "with open(\"interview.txt\") as file:\n",
        "    interview = file.read()\n",
        "\n",
        "interview[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VvNjnFpA2gf7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    chain.invoke({\n",
        "        \"context\": interview,\n",
        "        \"question\": \"Is reading papers a good idea?\"\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "yyv0EoJyDLSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csTqTilc2gf7"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"interview.txt\")\n",
        "text_documents = loader.load()\n",
        "text_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJHrcHS-2gf8",
        "outputId": "b7083267-be28-4bb1-a399-3a76d6ac96da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'interview.txt'}, page_content=\"I think it's possible that physics has exploits and we should be trying to find them. arranging some\"),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content='arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow,'),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content='buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligences'),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content=\"intelligences are kind of like the next stage of development. And I don't know where it leads to.\"),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content='where it leads to. Like at some point, I suspect the universe is some kind of a puzzle. These')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "text_splitter.split_documents(text_documents)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IdJYIbUp2gf8"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "documents = text_splitter.split_documents(text_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZHYMquf2gf8",
        "outputId": "acf5cd5a-3eb1-42b0-8228-0463749a1a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding length: 1536\n",
            "[0.01599571667611599, -0.019886909052729607, 0.01371423527598381, -0.013169214129447937, -0.027580568566918373, 0.014462053775787354, -0.013625510968267918, -0.0007193002384155989, 0.0008008948643691838, -0.01744065433740616]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "embedded_query = embeddings.embed_query(\"Wer ist Ralfs Bruder?\")\n",
        "\n",
        "print(f\"Embedding length: {len(embedded_query)}\")\n",
        "print(embedded_query[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YdWRgmLD2gf9"
      },
      "outputs": [],
      "source": [
        "sentence1 = embeddings.embed_query(\"Ralfs Bruder ist Axl\")\n",
        "sentence2 = embeddings.embed_query(\"Michaelas Bruder ist Paul\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McA_WYRW2gf9",
        "outputId": "2f31d740-8c19-488e-f879-c9c419b6ca4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.9093964737341363), np.float64(0.843505451391902))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
        "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
        "\n",
        "query_sentence1_similarity, query_sentence2_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docarray"
      ],
      "metadata": {
        "id": "3ybMgoOz8jcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vzooiuLF2gf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4ae5a5-6e96-4052-c6a3-a7d2c0ca2e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
            "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "vectorstore1 = DocArrayInMemorySearch.from_texts(\n",
        "    [\n",
        "        \"Ralfs Bruder heißt Axl\",\n",
        "        \"Michaela und Paul sind Geschwister\",\n",
        "        \"Dennis mag weiße Autos\",\n",
        "        \"Anna Mutter ist Lehrerin\",\n",
        "        \"Hektor fährt einen schwarzen Audi\",\n",
        "        \"Michaela hat zwei Geschwister\",\n",
        "    ],\n",
        "    embedding=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD7XZInT2gf-",
        "outputId": "e9d9fdbb-3bcb-473e-db32-d609f9b289ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(metadata={}, page_content='Ralfs Bruder heißt Axl'),\n",
              "  np.float64(0.9127635862951935)),\n",
              " (Document(metadata={}, page_content='Michaela und Paul sind Geschwister'),\n",
              "  np.float64(0.8209651848203824)),\n",
              " (Document(metadata={}, page_content='Michaela hat zwei Geschwister'),\n",
              "  np.float64(0.8025362350493098))]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "vectorstore1.similarity_search_with_score(query=\"Wer ist Ralfs Bruder?\", k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jt_ui5w2gf_",
        "outputId": "73825fc4-b54e-4c1e-e122-a1a5b28cd5c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Ralfs Bruder heißt Axl'),\n",
              " Document(metadata={}, page_content='Michaela und Paul sind Geschwister'),\n",
              " Document(metadata={}, page_content='Michaela hat zwei Geschwister'),\n",
              " Document(metadata={}, page_content='Hektor fährt einen schwarzen Audi')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "retriever1 = vectorstore1.as_retriever()\n",
        "retriever1.invoke(\"Wer ist Ralfs Bruder?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx8Liegh2gf_",
        "outputId": "2bfb09c4-004e-409e-d150-86a6bbfd13aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={}, page_content='Hektor fährt einen schwarzen Audi'),\n",
              "  Document(metadata={}, page_content='Dennis mag weiße Autos'),\n",
              "  Document(metadata={}, page_content='Ralfs Bruder heißt Axl'),\n",
              "  Document(metadata={}, page_content='Michaela hat zwei Geschwister')],\n",
              " 'question': 'Welche Farbe hat Hektors Auto?'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
        "setup.invoke(\"Welche Farbe hat Hektors Auto?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QFS2WV8f2ggA",
        "outputId": "f1cd555a-ba84-4164-959a-b7e10f95b0e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hektors Auto ist schwarz.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "chain = setup | prompt | model | parser\n",
        "chain.invoke(\"Welche Farbe hat Hektors Auto?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QmntjKf42ggA",
        "outputId": "c3aa351c-4a67-4fd3-b22f-567375242dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hektor fährt einen schwarzen Audi.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "chain.invoke(\"Welches Auto fährt Hektor?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ctfsZEPU2ggB"
      },
      "outputs": [],
      "source": [
        "vectorstore2 = DocArrayInMemorySearch.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "jpcxrRQi2ggB",
        "outputId": "8a1a1104-7ef4-4972-d293-551cb3c779ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Synthetic intelligence refers to advanced artificial intelligence systems that are seen as the next stage of development in AI. These systems are thought to possess capabilities that allow them to uncover and solve complex problems or puzzles within the universe. Unlike traditional forms of AI, synthetic intelligences are anticipated to engage in tasks that involve understanding emotions, creativity, and generating art and ideas autonomously.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "chain = (\n",
        "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | parser\n",
        ")\n",
        "chain.invoke(\"What is synthetic intelligence?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}