{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RalfH1388/genai-lecture/blob/main/genai_agents_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dieser Code muss nicht verstanden werden, er stellt lediglich sicher, dass\n",
        "# alle Ausgaben einer Zelle angezeigt werden (und nicht nur die letzte).\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "id": "svxo_fsaCknz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('apikey_rh')\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You're a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a limerick about the Python programming language.\",\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "response = completion.choices[0].message.content\n",
        "print(response)"
      ],
      "metadata": {
        "id": "28_rPIQC_IES",
        "outputId": "f8e55a26-3843-4e5f-d819-198b00504bd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a land where the code flows like wine,  \n",
            "Python's syntax is easy to sign.  \n",
            "With its libraries vast,  \n",
            "Developers cast  \n",
            "Their problems away with a line!  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 1: Define the response format in a Pydantic model\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "\n",
        "class CalendarEvent(BaseModel):\n",
        "    name: str\n",
        "    date: str\n",
        "    participants: list[str]\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 2: Call the model\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
        "        },\n",
        "    ],\n",
        "    response_format=CalendarEvent,\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 3: Parse the response\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "event = completion.choices[0].message.parsed\n",
        "event.name\n",
        "event.date\n",
        "event.participants"
      ],
      "metadata": {
        "id": "D5WOQdGN_rIT",
        "outputId": "50d52e6d-8b49-47b8-afe9-38260d50d6b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Science Fair'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Friday'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alice', 'Bob']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Das System funktioniert nach folgendem Ablauf:\n",
        "\n",
        "# Das LLM bekommt eine Anfrage („What's the weather like in Paris?“).\n",
        "# Es erkennt, dass dafür das get_weather-Tool nützlich ist.\n",
        "# Es generiert einen Funktionsaufruf (mit z. B. Koordinaten).\n",
        "# Deine externe Logik (Python-Code) führt diesen Aufruf aus.\n",
        "# Das Ergebnis wird zurückgegeben und in den nächsten Prompt eingespeist.\n",
        "# Das LLM generiert dann auf dieser Basis eine finale Antwort.\n",
        "\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\"\"\"\n",
        "docs: https://platform.openai.com/docs/guides/function-calling\n",
        "\"\"\"\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Define the tool (function) that we want to call\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "\n",
        "def get_weather(latitude, longitude):\n",
        "    \"\"\"This is a publically available API that returns the weather for a given location.\"\"\"\n",
        "    response = requests.get(\n",
        "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
        "    )\n",
        "    data = response.json()\n",
        "    return data[\"current\"]\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 1: Call model with get_weather tool defined\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"latitude\": {\"type\": \"number\"},\n",
        "                    \"longitude\": {\"type\": \"number\"},\n",
        "                },\n",
        "                \"required\": [\"latitude\", \"longitude\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "            \"strict\": True,\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "system_prompt = \"You are a helpful weather assistant.\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"},\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 2: Model decides to call function(s)\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "completion.model_dump()\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 3: Execute get_weather function\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "\n",
        "def call_function(name, args):\n",
        "    if name == \"get_weather\":\n",
        "        return get_weather(**args)\n",
        "\n",
        "\n",
        "for tool_call in completion.choices[0].message.tool_calls:\n",
        "    name = tool_call.function.name\n",
        "    args = json.loads(tool_call.function.arguments)\n",
        "    messages.append(completion.choices[0].message)\n",
        "\n",
        "    result = call_function(name, args)\n",
        "    messages.append(\n",
        "        {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
        "    )\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 4: Supply result and call model again\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "\n",
        "class WeatherResponse(BaseModel):\n",
        "    temperature: float = Field(\n",
        "        description=\"The current temperature in celsius for the given location.\"\n",
        "    )\n",
        "    response: str = Field(\n",
        "        description=\"A natural language response to the user's question.\"\n",
        "    )\n",
        "\n",
        "\n",
        "completion_2 = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    response_format=WeatherResponse,\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Step 5: Check model response\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "final_response = completion_2.choices[0].message.parsed\n",
        "final_response.temperature\n",
        "final_response.response"
      ],
      "metadata": {
        "id": "bS0v0pBbCa4d",
        "outputId": "31675328-fc15-4143-e71a-e03d28ba02ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndocs: https://platform.openai.com/docs/guides/function-calling\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-Bs12Ek987VwLIYDDIdLUF5LyTiBLb',\n",
              " 'choices': [{'finish_reason': 'tool_calls',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'message': {'content': None,\n",
              "    'refusal': None,\n",
              "    'role': 'assistant',\n",
              "    'annotations': [],\n",
              "    'audio': None,\n",
              "    'function_call': None,\n",
              "    'tool_calls': [{'id': 'call_xpcbkTnpB3M6S6kYicEn4pxa',\n",
              "      'function': {'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
              "       'name': 'get_weather'},\n",
              "      'type': 'function'}]}}],\n",
              " 'created': 1752213390,\n",
              " 'model': 'gpt-4o-mini-2024-07-18',\n",
              " 'object': 'chat.completion',\n",
              " 'service_tier': 'default',\n",
              " 'system_fingerprint': 'fp_34a54ae93c',\n",
              " 'usage': {'completion_tokens': 24,\n",
              "  'prompt_tokens': 66,\n",
              "  'total_tokens': 90,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.8"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature in Paris is 18.8°C with a wind speed of 6.8 m/s.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}