{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RalfH1388/genai-lecture/blob/main/genai_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval Augmented Generation (RAG)\n",
        "# ---\n",
        "# In diesem Beispiel erstellen wir ein RAG-System.\n",
        "# Warum ist RAG sinnvoll? Weil ein LLM nicht per se inhaltlich korrekten Inhalt\n",
        "# produziert, sondern wie ein \"stochastischer Papagei\" entlang seiner Trainings-\n",
        "# daten Tokens basierend auf vorherigen Tokens produziert.\n",
        "# Wenn wir uns sicher sein wollen, dass die Inhalte korrekt sind, brauchen wir\n",
        "# also andere Methoden. Und manchmal ist es ohnehin so, dass wir sehr spezielle\n",
        "# Informationen verarbeiten müssen (z.B. geheime firmeninterne Dokumente), von\n",
        "# denen das LLM sowieso nicht direkt etwas Bescheid weiß.\n",
        "# Die Grundidee eines RAG-Systems ist, dass ein Sprachmodell bei der\n",
        "# Beantwortung von Fragen externe Wissensquellen durchsucht und relevante\n",
        "# Informationen in seine Antwort integriert."
      ],
      "metadata": {
        "id": "UiQ1Su33M_Lf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4c9Oe7l32gf0"
      },
      "outputs": [],
      "source": [
        "# Wir wollen hier mit den LLMs von OpenAI arbeiten. Da wir ein Backend-System\n",
        "# entwickeln, hilft uns die UI-Version von ChatGPT nicht weiter, sondern wir\n",
        "# brauchen Zugriff zur Developer-API mittels API Key. Jeder von Euch hat von mir\n",
        "# entweder einen API Key von meinem persönlichen Account bekommen, oder nutzt\n",
        "# einen aus seinem eigenen Account. Dieser Key muss - falls Ihr in Google\n",
        "# Colab bleibt - als Secret hier hinterlegt werden, ansonsten in einem lokalen\n",
        "# Environment. In Google Colab müsst Ihr links auf das Schlüssel-Symbol klicken\n",
        "# und den Key dort copy pasten sowie dem Key einen Namen geben. Diesen Namen\n",
        "# nutzt Ihr dann hier in der Klammer:\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('apikey_rh')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai\n",
        "#!pip install openai\n",
        "#!pip install langchain-core"
      ],
      "metadata": {
        "id": "9u8WePp87ZQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IVLOVSkZ2gf1"
      },
      "outputs": [],
      "source": [
        "# Nun nutzen wir ein LLM von OpenAI, indem wir die API direkt ansprechen, in\n",
        "# diesem Fall das gpt-4o-mini:\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AeoTvWd52gf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc1cb4d6-4c8f-48b2-fead-67318019f694"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Der Sinn des Lebens ist eine komplexe und individuelle Frage, die viele Philosophien, Religionen und Wissenschaften unterschiedlich beantworten. Einige mögliche Perspektiven sind:\\n\\n1. **Philosophische Ansätze**: Philosophen wie Sokrates, Nietzsche oder Sartre haben verschiedene Sichtweisen entwickelt, die von der Suche nach Wissen, über die Schaffung eigener Werte bis hin zur Akzeptanz von Absurdität reichen.\\n\\n2. **Religiöse Perspektiven**: Viele Religionen bieten Antworten, die oft auf dem Glauben an einen höheren Zweck oder an eine göttliche Ordnung basieren. Beispielsweise glauben Christen, dass der Sinn des Lebens darin besteht, Gott zu dienen und Nächstenliebe zu praktizieren, während Buddhisten das Streben nach Erleuchtung als zentral erachten.\\n\\n3. **Humanistische Sichtweisen**: Aus einer humanistischen Perspektive könnte der Sinn des Lebens darin gesehen werden, das Leben zu genießen, persönliche Beziehungen aufzubauen, das Wohl anderer zu fördern und einen positiven Einfluss auf die Welt zu haben.\\n\\n4. **Wissenschaftliche Perspektiven**: Evolutionsbiologie und Neurowissenschaften betrachten den Sinn des Lebens oft in Bezug auf Überleben und Fortpflanzung. In dieser Sichtweise könnte der Zweck des Lebens einfach darin bestehen, Gene weiterzugeben.\\n\\nDie Antwort auf diese Frage hängt stark von persönlichen Überzeugungen, Erfahrungen und individuellen Lebenssituationen ab. Letztendlich könnte man sagen, dass der Sinn des Lebens von jedem Einzelnen selbst definiert werden kann.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 307, 'prompt_tokens': 14, 'total_tokens': 321, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrOvrRsXToQ6TG2tOoVBYPzGbLacj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6efd2be0-5349-434d-8f8a-69b139b52db0-0', usage_metadata={'input_tokens': 14, 'output_tokens': 307, 'total_tokens': 321, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Nun kann mit model.invoke() ein Prompt an die API geschickt werden, und das\n",
        "# in model eingestellte Modell liefert die Antwort:\n",
        "model.invoke(\"Was ist der Sinn des Lebens? Bitte fasse Dich kurz!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Man kann hier noch viel mehr Dinge einstellen:\n",
        "model2= ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.7,           # Kreativität (0 = deterministisch, 1 = kreativ)\n",
        "    max_tokens=100,            # Maximale Länge der Antwort\n",
        "    top_p=1.0,                 # Nucleus Sampling (Standard: 1.0)\n",
        "    frequency_penalty=0.0,     # Strafe für Wiederholungen\n",
        "    presence_penalty=0.0,      # Motivation, neue Themen zu bringen\n",
        "    request_timeout=30        # Timeout in Sekunden\n",
        ")\n",
        "model2.invoke(\"Was ist der Sinn des Lebens? Bitte fasse Dich kurz!\")"
      ],
      "metadata": {
        "id": "X47mBhb8UfvO",
        "outputId": "6ce138fd-f4d1-49d2-8760-d465138b90cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Der Sinn des Lebens ist eine tiefgehende und oft philosophische Frage, die Menschen seit Jahrhunderten beschäftigt. Die Antworten darauf sind vielfältig und hängen stark von individuellen Überzeugungen, kulturellen Hintergründen und persönlichen Erfahrungen ab. \\n\\nEinige mögliche Perspektiven sind:\\n\\n1. **Persönliche Erfüllung**: Viele Menschen finden Sinn im Streben nach persönlichen Zielen, Leidenschaften und Hobbys. Dies kann die Verwirklichung von Träumen, das Erlernen neuer', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 14, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrOwYFmhnWLD04NjBxULq0s8EA2x9', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None}, id='run--ab32e3f5-b9f7-45a7-8c08-1778e65a8b0a-0', usage_metadata={'input_tokens': 14, 'output_tokens': 100, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Man sieht jetzt im obigen Beispiel, dass etwas die Antwort kürzer geworden\n",
        "# ist, da wir die max_tokens auf 100 begrenzt haben.\n",
        "\n",
        "# Merke: oben haben wir den Code des Langchain OpenAI-Frameworks benutzt.\n",
        "# Es gibt natürlich die Möglichkeit, auch die OpenAI Original SDK zu verwenden:"
      ],
      "metadata": {
        "id": "GyNMw9mlVSkB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "m_CAXI3MV1zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY, timeout=30)  # hier wird der Timeout gesetzt\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Was ist der Sinn des Lebens? Bitte fasse Dich kurz!\"}\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        "    top_p=1.0,\n",
        "    frequency_penalty=0.0,\n",
        "    presence_penalty=0.0,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "GQb6P5-4V2pe",
        "outputId": "efc7fcde-1d46-4610-b16f-e68b36959e13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Der Sinn des Lebens ist eine tiefgründige Frage, die von verschiedenen Kulturen, Philosophien und Religionen unterschiedlich beantwortet wird. Manche Menschen finden Sinn im Streben nach Glück, in zwischenmenschlichen Beziehungen, in der Verwirklichung von Zielen oder in der Suche nach Wissen. Andere sehen den Sinn des Lebens in spirituellen oder religiösen Überzeugungen.\n",
            "\n",
            "Philosophische Ansätze reichen von Existenzialismus, der den Einzelnen dazu ermutigt, seinen eigenen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CwRyH2khV1jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = model | parser\n",
        "chain.invoke(\"Wie funktioniert ein Ottomotor? Bitte antworte in zwei bis drei Sätzen!\")"
      ],
      "metadata": {
        "id": "Vrgeja4wuYYs",
        "outputId": "c4d5af7f-67a6-466a-9d04-06e7887ae9f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ein Ottomotor funktioniert durch den Zyklus von Ansaugen, Verdichten, Arbeiten und Ausstoßen von Luft-Kraftstoff-Gemisch in den Zylindern. Während der Verdichtung wird das Gemisch komprimiert, und ein Zündfunke entzündet es, woraufhin die Explosion den Kolben nach unten drückt und mechanische Energie erzeugt. Anschließend wird die verbrannte Mischung durch den Auspuff ausgestoßen und der Zyklus beginnt von neuem.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Wie funktioniert ein Ottomotor? Bitte antworte in zwei bis drei Sätzen!\"\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JYNQq2kuRs5",
        "outputId": "fd1edadd-62e3-47b1-e015-22809ceebe46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ein Ottomotor funktioniert durch den vierstufigen Otto-Zyklus: Ansaugen, Verdichten, Arbeiten und Ausstoßen. Bei der Ansaugphase wird Luft und Kraftstoffgemisch in den Zylinder gezogen, anschließend wird es komprimiert und durch einen Zündfunken entzündet, wodurch eine explosionsartige Expansion entsteht, die den Kolben nach unten drückt. Schließlich wird die verbrannte Luft-Abluft-Mischung durch das Auslassventil nach außen geleitet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYsfQwu_2gf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c316fd73-31ca-4cb0-ce58-99560653c32d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ein Ottomotor funktioniert nach dem Viertaktprinzip, bestehend aus Ansaugen, Verdichten, Arbeits- und Ausstoßtakt. Während des Ansaugens wird ein Luft-Benzin-Gemisch in den Zylinder eingesogen, das dann im Verdichtungstakt durch den Kolben komprimiert wird. Die Zündung des Gemischs erfolgt durch einen Funken, wodurch der Kolben im Arbeitstakt nach unten gedrückt wird und der Zyklus mit dem Ausstoßtakt endet, in dem die verbrauchten Abgase ausgestoßen werden.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "bzyb8Q9j2gf3",
        "outputId": "5d326515-509b-4acd-f817-b343949530ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: \\nBeantworte die Frage basierend auf dem Kontext.\\nWenn Du die Frage nicht beantworten kannst, antworte \"Ich weiß es nicht\".\\n\\nContext: Ralfs Bruder heißt Axl.\\n\\nQuestion: Wer ist Ralfs Bruder?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Beantworte die Frage basierend auf dem Kontext.\n",
        "Wenn Du die Frage nicht beantworten kannst, antworte \"Ich weiß es nicht\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt.format(context=\"Ralfs Bruder heißt Axl.\", question=\"Wer ist Ralfs Bruder?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yLvqUhAb2gf4",
        "outputId": "e0c116a0-cc94-4aad-d847-f13c35c591dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ralfs Bruder ist Axl.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chain = prompt | model | parser\n",
        "chain.invoke({\n",
        "    \"context\": \"Ralfs Bruder heißt Axl\",\n",
        "    \"question\": \"Wer ist Ralfs Bruder?\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzNNtXgQ2gf5"
      },
      "outputs": [],
      "source": [
        "translation_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate {answer} to {language}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lGBkJ1xe2gf5",
        "outputId": "8837e23a-9968-47a9-855b-d1c28fe795a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ralf's brother Axl has two other siblings, so Ralf has a total of three siblings.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "translation_chain = (\n",
        "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
        ")\n",
        "\n",
        "translation_chain.invoke(\n",
        "    {\n",
        "        \"context\": \"Ralfs Bruder heißt Axl. Er hat zwei weitere Geschwister.\",\n",
        "        \"question\": \"Wie viele Geschwister hat Ralf?\",\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BLLqHtA2gf6"
      },
      "source": [
        "Let's read the transcription and display the first few characters to ensure everything works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XZC-Twgf2gf6",
        "outputId": "5455fc67-d921-43a1-d5f3-8bff9cc1fd34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I think it's possible that physics has exploits and we should be trying to find them. arranging some\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "with open(\"data_interview.txt\") as file:\n",
        "    interview = file.read()\n",
        "\n",
        "interview[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvNjnFpA2gf7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    chain.invoke({\n",
        "        \"context\": interview,\n",
        "        \"question\": \"Is reading papers a good idea?\"\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "yyv0EoJyDLSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csTqTilc2gf7"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"interview.txt\")\n",
        "text_documents = loader.load()\n",
        "text_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJHrcHS-2gf8",
        "outputId": "b7083267-be28-4bb1-a399-3a76d6ac96da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'interview.txt'}, page_content=\"I think it's possible that physics has exploits and we should be trying to find them. arranging some\"),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content='arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow,'),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content='buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligences'),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content=\"intelligences are kind of like the next stage of development. And I don't know where it leads to.\"),\n",
              " Document(metadata={'source': 'interview.txt'}, page_content='where it leads to. Like at some point, I suspect the universe is some kind of a puzzle. These')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "text_splitter.split_documents(text_documents)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdJYIbUp2gf8"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "documents = text_splitter.split_documents(text_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZHYMquf2gf8",
        "outputId": "acf5cd5a-3eb1-42b0-8228-0463749a1a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding length: 1536\n",
            "[0.01599571667611599, -0.019886909052729607, 0.01371423527598381, -0.013169214129447937, -0.027580568566918373, 0.014462053775787354, -0.013625510968267918, -0.0007193002384155989, 0.0008008948643691838, -0.01744065433740616]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "embedded_query = embeddings.embed_query(\"Wer ist Ralfs Bruder?\")\n",
        "\n",
        "print(f\"Embedding length: {len(embedded_query)}\")\n",
        "print(embedded_query[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdWRgmLD2gf9"
      },
      "outputs": [],
      "source": [
        "sentence1 = embeddings.embed_query(\"Ralfs Bruder ist Axl\")\n",
        "sentence2 = embeddings.embed_query(\"Michaelas Bruder ist Paul\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McA_WYRW2gf9",
        "outputId": "2f31d740-8c19-488e-f879-c9c419b6ca4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.9093964737341363), np.float64(0.843505451391902))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
        "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
        "\n",
        "query_sentence1_similarity, query_sentence2_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docarray"
      ],
      "metadata": {
        "id": "3ybMgoOz8jcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzooiuLF2gf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4ae5a5-6e96-4052-c6a3-a7d2c0ca2e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
            "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "vectorstore1 = DocArrayInMemorySearch.from_texts(\n",
        "    [\n",
        "        \"Ralfs Bruder heißt Axl\",\n",
        "        \"Michaela und Paul sind Geschwister\",\n",
        "        \"Dennis mag weiße Autos\",\n",
        "        \"Anna Mutter ist Lehrerin\",\n",
        "        \"Hektor fährt einen schwarzen Audi\",\n",
        "        \"Michaela hat zwei Geschwister\",\n",
        "    ],\n",
        "    embedding=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD7XZInT2gf-",
        "outputId": "e9d9fdbb-3bcb-473e-db32-d609f9b289ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(metadata={}, page_content='Ralfs Bruder heißt Axl'),\n",
              "  np.float64(0.9127635862951935)),\n",
              " (Document(metadata={}, page_content='Michaela und Paul sind Geschwister'),\n",
              "  np.float64(0.8209651848203824)),\n",
              " (Document(metadata={}, page_content='Michaela hat zwei Geschwister'),\n",
              "  np.float64(0.8025362350493098))]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "vectorstore1.similarity_search_with_score(query=\"Wer ist Ralfs Bruder?\", k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jt_ui5w2gf_",
        "outputId": "73825fc4-b54e-4c1e-e122-a1a5b28cd5c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Ralfs Bruder heißt Axl'),\n",
              " Document(metadata={}, page_content='Michaela und Paul sind Geschwister'),\n",
              " Document(metadata={}, page_content='Michaela hat zwei Geschwister'),\n",
              " Document(metadata={}, page_content='Hektor fährt einen schwarzen Audi')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "retriever1 = vectorstore1.as_retriever()\n",
        "retriever1.invoke(\"Wer ist Ralfs Bruder?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx8Liegh2gf_",
        "outputId": "2bfb09c4-004e-409e-d150-86a6bbfd13aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={}, page_content='Hektor fährt einen schwarzen Audi'),\n",
              "  Document(metadata={}, page_content='Dennis mag weiße Autos'),\n",
              "  Document(metadata={}, page_content='Ralfs Bruder heißt Axl'),\n",
              "  Document(metadata={}, page_content='Michaela hat zwei Geschwister')],\n",
              " 'question': 'Welche Farbe hat Hektors Auto?'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
        "setup.invoke(\"Welche Farbe hat Hektors Auto?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QFS2WV8f2ggA",
        "outputId": "f1cd555a-ba84-4164-959a-b7e10f95b0e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hektors Auto ist schwarz.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "chain = setup | prompt | model | parser\n",
        "chain.invoke(\"Welche Farbe hat Hektors Auto?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QmntjKf42ggA",
        "outputId": "c3aa351c-4a67-4fd3-b22f-567375242dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hektor fährt einen schwarzen Audi.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "chain.invoke(\"Welches Auto fährt Hektor?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctfsZEPU2ggB"
      },
      "outputs": [],
      "source": [
        "vectorstore2 = DocArrayInMemorySearch.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "jpcxrRQi2ggB",
        "outputId": "8a1a1104-7ef4-4972-d293-551cb3c779ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Synthetic intelligence refers to advanced artificial intelligence systems that are seen as the next stage of development in AI. These systems are thought to possess capabilities that allow them to uncover and solve complex problems or puzzles within the universe. Unlike traditional forms of AI, synthetic intelligences are anticipated to engage in tasks that involve understanding emotions, creativity, and generating art and ideas autonomously.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "chain = (\n",
        "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | parser\n",
        ")\n",
        "chain.invoke(\"What is synthetic intelligence?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}